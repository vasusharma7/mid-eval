%_____________________________________________________________________________________________ 
% LATEX Template: Department of Comp/IT BTech Project Reports
% Sample Chapter
% Sun Mar 27 10:25:35 IST 2011
%
% Note: Itemization, enumeration and other things not shown. A sample figure is included.
%_____________________________________________________________________________________________ 


{\let\clearpage\relax \chapter{Proposed Methodology/Solution}}

We went on to perform two experiments parallely for text segmentation - training models for ARU Net and CRAFT. While ARU Net produces baselines for the text, post-processing techniques are applied to reach at text-line level segmentation from the page\cite{3}. The CRAFT architecture produces character region and affinity scores which are also passed through post-processing methods to reach at word level bounding boxes.\cite{5}

The authors of the ARU Net trained the model mainly on handwritten historic documents. The model weight files avaialable are useful just for inference purpose while cannot be used for transfer learning. The pretrained weights work well on similar historic documents and produce descent baselines for simpler non-augmented handwritten documents but fails to find proper baselines for machine print documents with random distortions and augmentations. So, for dealing with all these problems, we came up to a custom dataset for training. The dataset we used consists of a mix of historic documents, IAM dataset and some internal confidential documents handpicked from the ones on which esablished OCR tools do very well.

The baselines for historic documents are annotated using some open source python scripts and DigiTexx as cited in the paper mentioned in Literature Review Section\cite{6}. The IAM database contains 13,353 images of handwritten lines of text created by 657 writers. The texts those writers transcribed are from the Lancaster-Oslo/Bergen Corpus of British English and it resembles real world handwritten data. It includes contributions from 657 writers making a total of 1,539 handwritten pages comprising of 115,320 words and is categorized as part of modern collection. The database is labeled at the sentence, line, and word levels. After running omnipage on the samples, we handpick the images for which we get accurate predictions for the lines and words and then form baselines using pre-processing methods on the word level bounding box outputs that we get from existing tools. The final dataset consisted of around 1024 images for training and 128 images for validation.

To tackle the problem of under performance on the augmented images and on the images which are not so clear, we introduced rigorous augmentations on the training data on the fly so as to match the real world data on which we have to perform inferences. We introduced elastic deformations, affine transformations, horizontal flips, random rotation, perspective transformations etc, completely replicating the real world inference data.

After collection of all the data and all the augmentations in place, we trained ARU Net from scratch without fine-tuning for around 200 epochs with 250 batch steps per epoch. The network learns to draw decent baselines even on training on a very small dataset and we get to see good baselines even after training for few epochs. The results start to saturate after 150 epochs.

The ground truths and the output of the network is a set of 3 images where in first image has baseline regions and the second image has vertical boundaries at the start and end of each baseline, particularly useful to identify the lines in multi-columnar documents.The third image is just the inverted image of the image obtained by combining first 2 images together.

After we get the baselines, we employ a post-processing technique to reach to the text segmentation. We super-impose the baselines obtained from ARU Net on top of the corresponding text in the image and as a result we connect all the words in a line with the baseline. This is followed by image cleaning and discarding some pixels based on thresholds obtained by hyper-parameter tuning and utlimately we perform connected component analysis where in we identify the regions which are connected together, which in our case are the differnet words in a line. The output from the connected component analysis is passed on to detect the minimum area rectangle which will completely surround the connected region and hence we get the bounding boxes around the words in a line.

For CRAFT based approach, we planned to train the model both using supervised learning and semi-supervised learning. As for now, the training for supervised learning method has been done. For superivised learning, we need a dataset with character level bounding boxes and word labels. We prepared custom dataset using IAM data avaialable and some handpicked proprietary images. To completely replicate the real world exmaple cases, we drew synthetic baselines below the IAM images. The final dataset consisted of around 1800 images which were put on training and 200 images for validation set.

In every training batch during epochs,we also used synthetic dataset used by the authors of CRAFT paper which consists of words placed randomly on some scenic backgrounds. One sample from this dataset was combined with 3 instances of images from the custom dataset generated. This was done so that the model doesn't lose the knowlege it has gained from the previous dataset. So the network saw around 2500 images in each epoch.

We also introduced a number of augmentations to replicate the real world data. Some of the augmenatations used were functional (sin) deformations, shear tranform, introducing random lines, random brightness and noise, random rotation and 3D perspective shifts. Considerable amount of time was spent to tune the hyperparameters used in augmentations since some of the augmentations involve distortion of character regions and hence parallely affect the region scores and affinity scores ground truths.

The training loops of CRAFT being very resource hungry, take very long time to complete.We decided to go with finetuing CRAFT,by borrowing weights from the model which was trained on synthetic data by the authors.We were able to train for around 100 epochs and studied the results on by visually inspecting the outputs on the test set images selected based on edge cases. 
The model output is a set of 2 images - region and character scores which are super-imposed on top of each other, as a result the different character regions of a word get connected with affinity scores in between and eventually this is passed through same post-processing techniques used for ARU Net to get the exact bounding boxes around the words.


We were not able to get discrete bounding boxes for some words and figures i.e. the region and affinity maps in the output of the model were such that there is more than one resultant bounding boxes for a single word or a numerical figure.This is a crucial problem to resolve from business perspective as it would also affect the later stages of OCR pipeline. Also, there were a lot of cases where the commas,full-stops and other symbols in the text were getting missed out. Further, there were no region and affinity scores for a number of words in handwritten text.

To tackle all these problems, we altered the network architecture of original CRAFT model and introduced a third score map called as word map.Along with producing the region and affinity scores maps, we also output word score map, completely highlighting the regions with words in the text.The necessary changes were also done in the calculation of loss function where we introduced third cost.In the post-processing steps, we take all three score maps together - word, region and affinity maps to produce the final word bounding boxes.

We did several modifications to the network.We began by making a copy of the last 5 convolutional layers to produce the word score map. We trained the network, keeping the bottom layers(VGG-net and up-convolutional layers) and the other set of convolutional layers for region and affinity score maps frozen.

In the next iteration, we went on to make a copy of all the UP-Convolutional layers and the final 5 convolutional layers to train the network for predicting the word map. We kept the other set of up-convolutional layers and the last convolutional layers frozen for region and affinity scores.

For training the network, we generated the word region score maps in the same way we generate region and affinity maps, with some adjustments to heights and widths of the words. The final word maps were generated after doing several visual inspections of various iterations of word scores generated for a set of sample images.

The improvements in the results after the introduction of third cost are discussed in the next section.

%____duced_________________________________________________________________________________________ 
