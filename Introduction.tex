%_____________________________________________________________________________________________ 
% LATEX Template: Department of Comp/IT BTech Project Reports
% Sample Chapter
% Sun Mar 27 10:25:35 IST 2011
%
% Note: Itemization, enumeration and other things not shown. A sample figure is included.
%_____________________________________________________________________________________________ 

\setstretch{1.5}
\chapter{Introduction}
Optical characeter recognition (OCR) generally refers to the process of recognizing the text in images of scanned papers, digital photographs, computer screens etc. The text can be machine printed or handwritten. OCR engines find a lot of applications like document archival, indexing, information extraction etc in the fields like medical records, financial and banking records. These usecases demand high accuracy/precision from OCR engines especially in cases of sensitive information.

There are serveral optical character recognition engines available - both community driven ie. free ones as well as subscription based. Some of the most popular Optical Character Recognition Engines include Tesseract, OpenCV, Omnipage, Google OCR and Microsoft's Aforge. Tesseract is a very popular engine available on various operating systems. It is a free software, released under the Apache License. In many cases, Tessaract's results are not as accurate as some other commercial solutions available in the market. Also, it doesn't do well with images affected by artifacts including partial occlusion, distorted perspective, and complex background. And most importantly detecting handwriting.

Several commercial tools like Omnipage, Abby, Google offer relatively good Optical Character Recogition on machine print images but relatively mixed results on handwritten text or in situations where the text is not perfectly aligned. Also in some cases, the user interface is not so intuitive for naive users. Several other subscription or paid softwares offering Optical Character Recognition are designed to be very generic and do not effectively address the needs and use cases that the company targets.

Over the years there have been extensive research proposing various deep learning based solutions for OCR. There have been solutions proposing the use of Convolutional Neural Networks (CNN) with Recurrent Neural Networks (RNN) for text recognition. While some other solutions propose transformer architecture for the task. Work has also been done applying LSTMs with attention mechanism to recognise characters better. Even with the application of these various approaches, handling of various image artifacts and handwritten characters still pose many challenging situations.

The work done here mainly pertains to the text segmentation part of a typical OCR pipeline and specifically tries to address handwritten text and certain complex cases of machine print data. Several approaches have been discussed in the subsequent sections. Segmentation here refers to detecting the regions consiting of words and lines out of the complete image that narrows down the problem as well as helps to do better OCR by reducintg errors in subsequent steps of of word-level recognition. Based on our literature survey - we narrowed down on two differnt approaches for text segmentation - CRAFT and ARU-Net.

Taking a step back, problems in the Computer Vision domain can be divided into 3 categories - Image Classification, Object Detection and Image Segmentation. Of all these 3, Image Segmentation poses a completely different set of problems. It involved labeling each pixel in the input image and the fact that the images can be 1000s of pixels in height and width makes it very expensive to have an output for each pixel. But using the advantage of Convolutional Neural Networks, the problem becomes a lot more tractable. There have been efficient networks developed over the years, one of them being U-Net for tackling the problem in a less-expensive way. ARU Net and CRAFT build on top of U-Net for text extraction using segmentation of images.

%_____________________________________________________________________________________________ 
