%_____________________________________________________________________________________________ 
% LATEX Template: Department of Comp/IT BTech Project Reports
% Sample Chapter
% Sun Mar 27 10:25:35 IST 2011
%
% Note: Itemization, enumeration and other things not shown. A sample figure is included.
%_____________________________________________________________________________________________ 

\setstretch{1.5}
\chapter{Introduction}
Optical characeter recognition is the process of reading the text on a piece of printed paper or on a piece of computer screen.The text can be in machine print form or handwritten format. Optical Character recognition engines find a lot of applications in case of maintaining an electronic copy of handwritten documents, recognising and preserving the text from an image which can be of high importance like medical records,requiring high accuracy like financial documents of Banks or can be of generic use like Invoices, bills. So, the problem of Optical Character reognition requires accuracy and high precision especially in cases of sensitive information.

There are serveral optical character recognition engines available - both community driven ie. free ones as well as some subscription based. Axis Technical Group have their proprietary version of OCR developed for internal needs and specific use cases dealt by the company. The most popular Optical Character Recognition Engines include Tesseract, OpenCV, Omnipage, Google OCR and Microsoft's Aforge. Tesseract is the most popular optical character recognition engine for various operating systems. It is free software, released under the Apache License. But the OCR is not as accurate as some commercial solutions available in the market. Also, it doesn't do well with images affected by artifacts including partial occlusion, distorted perspective, and complex background. And most importantly it fails to detect handwritings.

Several paid tools like Omnipage offer relatively good Optical Character Recogition on machine print images while fail to perform good on handwritten text or on images in which the text is not perfectly aligned. Also the user interface is not so intuitive and complex for naive users and is available on on Windows. Several other subscription or paid softwares offering Optical Character Recognition are very designed to be very generic and not suited for the internal needs of Axis Technical Group where we deal mostly with documents and handwritten/machine print records as input for OCR.

Over the years there have been extensive research proposing various deep learning based solutions for OCR. There have been solutions proposing the use of Convolutional Neural Networks with Recurrent Neural Networks (RNN) for OCR. While some other solutions also propose the use of Transformers for the task. Work has also been done to use LSTMs with attention mechanism to recognise characters better. Convolutional Neural Networks to extract latent representations of input images followed by LSTM network and Connectionist Temporal Classification Loss have proved to be most effective method for doing OCR using deep learning. While there are many state of the art propiertary tools developed within Axis Technical tools based on deep learning techniques which give exceptional results with machine print and simpler documents, the area of handwritten character recognition still poses some problems and handwriting cases get missed out in certain places.

There are several line and word OCR deep learning models developed and worked upon within the company. The work done from here on is mainly to improve the OCR for handwritten data and certain complex cases of machine print data in which the text is not perfectly aligned. Several approaches have been discussed in the subsequent sections while the focus lies on segmentation approach where the page or document is segmented into parts consisting of handwriting and then Line and Word OCR models are applied on the segmented part which have really good accuracy. Detecting the regions consiting of words and lines out of the complete page narrows down the problem as well as helps to do better OCR by reducintg errors in subsequent steps of Word OCR due to joined/comnined words written in handwritten text and identifying/segmenting them correctly. We explore two differnt approaches for doing text segmentation - CRAFT and ARU-Net.

Taking a step back, problems in the Computer Vision domain can be divided into 3 categories - Image Classification, Object Detection and Image Segmentation. Of all these 3, Image Segmentation poses a completely different set of problems. It involved labeling each pixel in the input image and the fact that the images can be 1000s of pixels in height and width makes it very expensive to have an output for each pixel. But using the advantage of Convolutional Neural Networks, the problem becomes a lot easier. There have been efficient networks developed over the years, one of them being U-Net for tackling the problem in a less-expensive way. ARU Net and CRAFT build on top of U-Net for text extraction using segmentation of images.

%_____________________________________________________________________________________________ 
