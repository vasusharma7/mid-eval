%_____________________________________________________________________________________________ 
% LATEX Template: Department of Comp/IT BTech Project Reports
% Sample Chapter
% Sun Mar 27 10:25:35 IST 2011
%
% Note: Itemization, enumeration and other things not shown. A sample figure is included.
%_____________________________________________________________________________________________ 

We trained ARU Net on historical data, as done by the authors in the paper as well as on custom document data generated by us.After training ARU Net for 100 epochs just on the historical data with no augmentation, we get a base model which performs good on simple documents without any augmentation but misses out the lines in the documents which are randomly oriented and have noise.After 100 epochs, the average loss came to be around 0.05438. This was done to reach to the level of the baseline model provided by the authors. Then after adding augmentations and training on the mixed set of data from IAM, some proprietary images and hostoric documents, it bacame robust on all sorts of images agnostic of noise,distortions etc. After 200 epochs, the average validation loss came to be around 0.07226.Further training of the model, decreases the loss but the effect on the baselines produced is not so considerable in terms of final post-processed outputs we acheive and it saturates after around 110 epochs, the model with best results is also obtained on 110th epoch.The graphs attached here are for training on custom data.

Although the ARU Net can work on images of any size, we found out that keeping the size fixed (768x768px in our case)  gives better results.We also trained just U-Net, R-UNet(with residual connections) and AR-UNet(with residual connections and Attention) separately and found out that ARU Net works best to capture better representations and to reach at better baselines.

As far as inferennce results are concerned, the trained model does a descent job on prediction of baselines in most of the cases of machine print but the post processing results using connected component analysis are not accurate in all the cases, we get two boxes for a word/line sometimes and sometimes the word boxes spread to the line below, leading to inaccurate character recognitions in the subsequent steps.Some of the results are attached here with.For handwritten documents which already have lines under the text(lines present in notebook), the baseline predictions are not good enough in those cases.

{\Large  \textbf{ARU Net: Graphs}}

\begin{figure}[H]
	\includegraphics[width=475pt,height=275pt]{Training Loss ARU Net.png}
	\caption{Average Training Loss: ARU Net}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=475pt,height=275pt]{Validation Loss ARU Net.png}
	\caption{Validation Loss: ARU Net}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=475pt,height=275pt]{in.jpg}
	\caption{Input: ARU Net}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=475pt,height=275pt]{out.jpg}
	\caption{Output: ARU Net}
\end{figure}


\begin{figure}[H]
	\includegraphics[width=475pt,height=275pt]{res.jpg}
	\caption{Intermediate Result: ARU Net}
\end{figure}


\begin{figure}[H]
	\includegraphics[width=475pt,height=275pt]{res_boxes.jpg}
	\caption{Bounding boxes: ARU Net}
\end{figure}

Shifting discussion to CRAFT network, the baseline model we started fine-tuning with, was trained on just syhthetic data.Synthetic data was very different than document data where we have hundreds of words in a page as compared to just a few words in syntheic data.Also the size of the words is comparitively small as compared to synthetic dataset.The baseline model was not able to perform good on augmented docuemnts in which text is at random angles.In all, the performance on the document data was not so great.We trained our model for around 100 epochs. An epoch takes around 90-100 minutes to complete and we analysed the results after every epoch. After certain epochs, the results start to degrade rather than improving,this can be due to the reason that the character level bounding boxes in the training data were not accurate and we were doing fully supervised learning of CRAFT.

In the first run, we didn't combine the input data with syhthetic data as used by the authors and as a result, the network started to forget the past learned information and performed bad even on the examples the baseline model performed good, although the results on the handwritten documents improved a bit.

In second phase, in every batch, we combined our custom training data with synthetic data used for training the baseline model we started with,used in the ratio of 3:1 in every batch. The results of training the network with this change helped to stay good on the cases where baseline performs good as well as get better at handwritten text. There are still some issues in recognising the text in the handwritten documents in which ruling lines are present in the paper, for which the model fails to recognise the words.But the results of recognising the words on plain paper are quite good.Certain issues also exist in machine print documents where the CRAFT model fails to recognise small characters like comma,hyphens,points,single characters and it becomes extremely critical in certain business documents.The sample result images are attached here with. 

We also tuned the hyperparametes required for connected component analysis and obtaining words from region and affinity scores - link threshold, region threshold and text threshold. Region threshold filters out the pixels regions below certain value and link threshold does that for affinity scores. After combining region and affinity scores, we do connected component analysis and find a large number of components and then we use text threshold to select the appropirate components for finding the minimum area rectangles.For our use case, we selected text threshold as 0.3, link threshold as 0.3 and region threshold as 0.4.

We have deployed the best epoch model which feeds in Word OCR model with the bounding boxes of all the words present in the page.The API is being used internally for testing. 

{\Large  \textbf{CRAFT: Graphs}}

\begin{figure}[H]
	\includegraphics[width=475pt,height=275pt]{Training Loss CRAFT.png}
	\caption{Average Training Loss: CRAFT}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=475pt,height=275pt]{Validation Loss CRAFT.png}
	\caption{Validation Loss: CRAFT}
\end{figure}


\begin{figure}[H]
	\includegraphics[width=475pt,height=275pt]{craft_mask.jpg}
	\caption{Masked output: CRAFT}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=475pt,height=275pt]{craft_out.jpg}
	\caption{Bounding Boxes: CRAFT}
\end{figure}

%_____________________________________________________________________________________________ 
